""" importation des biblioth√®ques n√©cessaires """

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Interface Streamlit
st.title("üì• T√©l√©charger les donn√©es scrap√©es sur Expat-Dakar")
st.write("S√©lectionnez la cat√©gorie et le nombre de pages √† scraper.")

# fonction de chargement des donn√©es d√©ja scrap√©es
def load_data(dataframe, title, key):
    st.markdown("""
    <style>
    div.stButton {text-align:center}
    </style>""", unsafe_allow_html=True)

    
    if st.button(title,key):
        st.subheader('Donn√©es scrap√©es')
        st.write('Dimensions des donn√©es: ' + str(dataframe.shape[0]) + ' lignes et ' + str(dataframe.shape[1]) + ' colonnes.')
        st.dataframe(dataframe)

# d√©finir quelques styles li√©s aux box
st.markdown('''<style> .stButton>button {
    font-size: 12px;
    height: 4em;
    width: 30em;
}</style>''', unsafe_allow_html=True)

# ajouter des filtres par √©tat, adresse et prix pour les donn√©es

st.sidebar.markdown('Filtres')
Etat = st.sidebar.selectbox('Etat', ['Neuf', "D'Occasion" , 'Venant', 'Reconditionn√©'])
Adresse = st.sidebar.selectbox('Adresse', ['Thi√®s', 'Mbour', 'Saint-Louis', 'Touba', 'Kaolack', 'Ziguinchor', 'Louga', 'Fatick', 'Diourbel', 'Kolda', 'Tambacounda', 'Matam', 'Kaffrine', 'K√©dougou', 'S√©dhiou'])
Prix = st.sidebar.slider('Prix', 0, 1000000, (0, 1000000))

# activer les filtres
def filter_data(dataframe, Etat, Adresse, Prix):
    filtered_data = dataframe
    if Etat != 'Tous':
        filtered_data = filtered_data[filtered_data['Etat'] == Etat]
    if Adresse != 'Tous':
        filtered_data = filtered_data[filtered_data['Adresse'] == Adresse]
    filtered_data = filtered_data[(filtered_data['Prix'] >= Prix[0]) & (filtered_data['Prix'] <= Prix[1])]
    return filtered_data

# Charger les donn√©es
load_data(pd.read_csv('Beautifoul_Soup_data/base_donnee_url1.csv'), 'Donn√©es sur les r√©frig√©rateurs-congelateurs', '1')
load_data(pd.read_csv('Beautifoul_Soup_data/base_donnee_url2.csv'), 'Donn√©es sur les climatisations', '2')
load_data(pd.read_csv('Beautifoul_Soup_data/base_donnee_url3.csv'), 'Donn√©es sur les cuisini√®res-fours', '3')
load_data(pd.read_csv('Beautifoul_Soup_data/base_donnee_url4.csv'), 'Donn√©es sur les machines-√†-laver', '4')
